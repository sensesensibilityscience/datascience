{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f900e-0ada-44f2-b610-ffa398b66afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY -- Install this if you get an error in 1.2. Let me know if it errors and I'll find a work around without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3d157-20dd-45a2-b674-adbfe5a42bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d12f8-98e6-4985-ac27-14936c6fc35a",
   "metadata": {},
   "source": [
    "# Model Building [student]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd94e89-f6dc-4e5e-bcf3-7bd450ef1144",
   "metadata": {},
   "source": [
    "In this notebook, you will work with timeseries data, starting with no other context. Your goal is use the raw data to build up to a robust model. We ask that you complete the content of this notebook linearly for the best learning experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bdf90-2675-44b5-83b7-5c8c7385e784",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ae2a7-2274-4ac6-ba76-962bf0eb5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell. \n",
    "import numpy as np\n",
    "# plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from student.hidden import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38af299-ad7c-458c-a198-e64252c16069",
   "metadata": {},
   "source": [
    "Let's start by loading the dataframe, which has been cleared of any contextual details. Feel free to experiment with timeseries_data however, but for now, no other information will be given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85e98b-e7ec-46ca-8936-1e3a24319388",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6670bd-df69-4048-b1d7-5cb265a9db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd756d77-50e9-484c-9012-7122d3cb9a10",
   "metadata": {},
   "source": [
    "For easier access later, let's store the first column values in `xdata` and second column values in `y_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87255f01-95df-4e1f-8beb-d6b6f4ccb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array(timeseries_data['time'])\n",
    "ydata = np.array(timeseries_data['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052a301-8d05-41c1-929f-83dee0be61ed",
   "metadata": {},
   "source": [
    "## Part 1: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1c6ee-2612-4265-878a-77a9fb51fedc",
   "metadata": {},
   "source": [
    "In this section of the notebook, we will visualize, analyze and fit our data to a model and investigate whether our model is good. To begin, let's plot our timeseries data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b377e-2776-400c-9c5e-ef0cc17606e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4)) \n",
    "plt.plot(xdata, ydata, '.')\n",
    "plt.xlabel('time') \n",
    "plt.ylabel('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d65b96-966f-4ee4-98e2-292d56ae06af",
   "metadata": {},
   "source": [
    "_Use this space to note any initial observations you have about the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68848d8-1d59-4ae1-9582-f41f77bb47ca",
   "metadata": {},
   "source": [
    "### 1.1 A Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d87fd-0df6-42b0-9ceb-d3516c837f65",
   "metadata": {},
   "source": [
    "**Question 1.1.1**: If you had to explain what value you'd expect at any given time, how could you do it? Think about how this representation helps us understand the dataset's general behavior or trend without getting lost in the specifics of each data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a92c0d-1d4e-430a-bbd4-08575d904f28",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b17def-9da8-4a67-88f9-9418bb6978de",
   "metadata": {},
   "source": [
    "We will create a constant model, that asssumes, despite the ups and downs in the data, there's an average value that represents the entire dataset reasonably well over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b6374-bc5d-4d78-9102-82fe90630e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this cell.\n",
    "average_value = np.mean(ydata)\n",
    "print(\"Average value is \" + str(average_value))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(xdata, ydata, '.')\n",
    "plt.axhline(y=average_value, color='r', linestyle='-') \n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d085b-60a2-4507-b609-46e2b0f11626",
   "metadata": {},
   "source": [
    "**Question 1.1.2:** In this model, how would you define the the signal? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af874f0b-d308-4e32-ac7e-7d7bccf6ca72",
   "metadata": {},
   "source": [
    "_Replace this with your answer._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9927b5-3626-4fa6-a223-912c498c718a",
   "metadata": {},
   "source": [
    "We can now summarize the entire dataset with a single number, giving us a baseline to compare patterns, observe deviations from the norm, and consider more parameters to build more complex models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaed170-14fc-4da1-9115-a83b1b055531",
   "metadata": {},
   "source": [
    "### 1.2 Adding More Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b2095-6631-4fdc-a95e-55ef7bad8368",
   "metadata": {},
   "source": [
    "**Question 1.2.1**: Based on the model you built above, describe what patterns and trends you notice? What mathematical function do you know that best mimics the pattern applied to the data above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2920f41-93ef-4b25-b83f-bd6258a245b3",
   "metadata": {},
   "source": [
    "_Replace this with your answer._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fb6ab-2ad8-4127-b8d1-9c556799b599",
   "metadata": {},
   "source": [
    "One function we can use is the cosine function, a good choice when working with data that looks periodical (i.e. occurs in phases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa47ef-5078-49e4-8d45-39dac11eefd6",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = A \\cos(B(x - C)) + D\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ae30e-62f6-4cf8-b6c2-148929294d24",
   "metadata": {},
   "source": [
    "Providing initial guesses for more complex models can help guide the computational process towards a more accurate and efficient solution. Use the widget below to experiment with what you can use as your intial guesses for the parameters A, B, C, and D. Don't worry about fitting the perfect model, a rough start is to get started will be good enough for our optimizing function later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b0a5a-23c1-415f-85f3-73750c342f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this cell.\n",
    "cosine_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e506b9c-9cfc-48d7-8d69-b64a9ec0f5d4",
   "metadata": {},
   "source": [
    "**Question 1.2.2**: Assign the values you choose for A, B, C, and D to `guess`, in that order, as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83dafde-a55d-4ce9-a92a-d99559cf8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09691605-a26c-4cd7-ab9b-ac34a9723257",
   "metadata": {},
   "source": [
    "Using the values for A, B, C, and D above as our guesses, let's find the best parameters that minimize error. This may be unfamiliar, but we will leverage `curve_fit` function from the scipy.optimize library which finds the best fit model (given we provide good starting point), doing most of the heavylifting for us. You can read the documentation here for [curve fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) if you're curious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb766c-9505-4a4f-bf2c-6db20bb3a180",
   "metadata": {},
   "source": [
    "**Question 1.2.3**: Fill in the code for `cos_func` which the specific shape of our curve given some paramters. Then, use that to define `fit_cosine`, which is the model that will be plotted over the data.\n",
    "\n",
    "_Hint: You'll know your guesses were good if the model is nicely fit to the data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4187b67-0cdf-462d-bcc8-9a6f334a5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide what students should code here, how much scaffolding should be given.\n",
    "plt.figure(figsize=(12, 6)) \n",
    "\n",
    "def cos_func(x_data, A, B, C, D):\n",
    "    # REPLACE ... WITH YOUR CODE\n",
    "    ...\n",
    "\n",
    "\n",
    "#Here, curve_fit finds the best values for each parameter of our model. Do not change this part of the code.\n",
    "parameters, _ = curve_fit(cos_func, xdata, ydata, p0=guess)\n",
    "fit_A = parameters[0]\n",
    "fit_B = parameters[1]\n",
    "fit_C = parameters[2]\n",
    "fit_D = parameters[3]\n",
    "\n",
    "# REPLACE ... WITH YOUR CODE\n",
    "fit_cosine = ...\n",
    "\n",
    "# DO NOT CHANGE THIS CODE\n",
    "plt.plot(xdata, ydata, '.', label='data')\n",
    "plt.plot(xdata, fit_cosine, '-', label='fit')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34da072e-d8f5-45f1-ae04-8f8c0e9c6945",
   "metadata": {},
   "source": [
    "Nice! Our model looks more accurate to our data now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5eb48-4393-48f3-ab62-ea6744900da7",
   "metadata": {},
   "source": [
    "### 1.3 Evaluating goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080b258-f531-4284-9ee2-d6a15c41ceac",
   "metadata": {},
   "source": [
    "With more parameters, our model looks better fit to the data. However, it's crucial to ask if the chosen model, like a cosine function in this case, truly reflects the underlying patterns of the data. Do we need to make the model more complex or do we have too many parameters and risk overfitting? How can we determine if what we have right now is a good model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b84257-c740-4509-a68e-7be6827092f8",
   "metadata": {},
   "source": [
    "_Use this space to write down any ideas you have_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f603cd1-32e7-4fc8-a110-5a347dfbdb73",
   "metadata": {},
   "source": [
    "The approach we will use is evaluating goodness of fit, checking whether our data is likely to be from a specific theoretical distribution we've defined. For example, you may have seen or worked with tests such as chi-square or coefficient of determination (R-squared). Our approach will involve using error bars.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6b2f3-e0ca-4b36-a4ed-356b79e5c519",
   "metadata": {},
   "source": [
    "**New information**: The data we are working with is about deaths counts. Each point represents the death count for a given week. No information about the time period will be given yet. Week 0 is some start date and the following values represent the subsequent weeks in the time period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e959a14-2802-4d54-9a5d-e19003164e02",
   "metadata": {},
   "source": [
    "For each point, we are 68% confident that the true value was +/- 1000 (i.e. a 68% error bar). To confirm, this is resonable as for any given week, we are staying we are 68% confident that the true count of deaths is plus or minus 1000, as some deaths go unaccounted for, are registered in following weeks, and other factors that influence error. Here's what that looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832ec56-ce4c-4286-80f4-7fa565f82fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this cell\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(xdata, ydata, yerr=1000, fmt='.', label='data', ecolor='black', capsize=5)\n",
    "plt.plot(xdata, fit_cosine, '-', label='fit')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb9dc4-c8b1-4eff-8103-989b5dbad601",
   "metadata": {},
   "source": [
    "**Question 1.3.1**: When we create our model, we want it to pass close to about 68% of our data points. Answer why you think so below. In your response, consider what it means about our model if our line doesn't pass through roughly 68% of our data? What if passes through more than 68% of points?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14f5b0-4295-4942-ae63-24e3379f1cea",
   "metadata": {},
   "source": [
    "_Replace this text with your answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d10344-9ff8-4123-a1f9-5fad4659d8bd",
   "metadata": {},
   "source": [
    "Now, let's actually calculate that percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfd854-d6fa-4062-aea5-3c2093c8c502",
   "metadata": {},
   "source": [
    "**Question 1.3.2**: Fill in the following code to calculate the percent of error bars our model passes through. Set that value equal to `percentage_passes`. You might find it helpful to use `fit_cosine`, `yerr`, `ydata`, and `xdata` in your answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f45f4-2f89-4433-b8b6-821d09d555b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yerr = 1000 # This is the +/- 1000 given to you. \n",
    "\n",
    "# REPLACE ... WITH YOUR CODE\n",
    "error_bar_passes = ...\n",
    "total_points = ...\n",
    "percentage_passes = ...\n",
    "\n",
    "print(f\"The fit line passes through {error_bar_passes} error bars out of {total_points} points.\")\n",
    "print(f\"Percentage: {percentage_passes:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84c4913-0136-4df0-9be3-1454f83ade51",
   "metadata": {},
   "source": [
    "**Question 1.3.3**: Based off the percent of error bars, do you think we should add more complexity? If so, what pattern in the errors do you notice that we could address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef600df3-27a7-4215-b5d1-7450abaf360b",
   "metadata": {},
   "source": [
    "_Replace this text with your answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9b1af-22e9-4b93-86de-172234422378",
   "metadata": {},
   "source": [
    "We will add a tilt to our cosine model, such that new model is modelled by a combination of the cosine and linear components. Specifically, _D_ represents the coefficient of the linear term and _E_ represents the y-intercept of the linear term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46604d0-daf7-48d7-90a1-ba42a7aab8be",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)=A\\cos(Bx+C)+Dx+E\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8caa90-4e12-48a4-8682-1f53394683b0",
   "metadata": {},
   "source": [
    "**Question 1.3.4**: Let's apply what we did in 1.2.3 to our new model with the additional parameter. Then, calculate the new percent of error bars that the fitted model passes through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae28454-10dc-4fb0-9559-da32a7c4adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tilted_cosine(x, A, B, C, D, E):\n",
    "    # REPLACE ... WITH YOUR CODE\n",
    "    ...\n",
    "    \n",
    "initial_guess = [max(ydata) - min(ydata), np.pi/200, 0, 0, np.mean(ydata)]\n",
    "\n",
    "parameters, _ = curve_fit(tilted_cosine, xdata, ydata, p0=initial_guess)\n",
    "fit_A = parameters[0]\n",
    "fit_B = parameters[1]\n",
    "fit_C = parameters[2]\n",
    "fit_D = parameters[3]\n",
    "fit_E = parameters[4]\n",
    "\n",
    "# REPLACE ... WITH YOUR CODE\n",
    "fit_data_with_tilt = ...\n",
    "\n",
    "# DO NOT CHANGE \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(xdata, ydata, yerr=1000, fmt='.', label='data', ecolor='black', capsize=5)\n",
    "plt.plot(xdata, fit_data_with_tilt, '-', label='fit')\n",
    "plt.legend()\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45706e-d1da-49f1-a216-7e96db053d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "yerr = 1000 \n",
    "\n",
    "# REPLACE ... WITH YOUR CODE\n",
    "error_bar_passes = ...\n",
    "total_points = ...\n",
    "percentage_passes = ... \n",
    "\n",
    "print(f\"The fit line passes through {error_bar_passes} error bars out of {total_points} points.\")\n",
    "print(f\"Percentage: {percentage_passes:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c5605-225d-4e0a-9cc7-051de68a7db9",
   "metadata": {},
   "source": [
    "**Question 1.3.5**: What did adding more complexity to our model do? How do you now feel about calling our current model \"a good model\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42847279-204f-4783-aae2-ac021ce1b602",
   "metadata": {},
   "source": [
    "_Replace this text with your answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8f847-91ca-4b27-87e7-d8b3cc3cb8dd",
   "metadata": {},
   "source": [
    "### END HERE (4/11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee442e6-05f6-4320-af5f-cd18eb584cf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 2: Finding a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566d9b4-7a4b-4e27-9b7e-4685d554de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_xdata = (excessdeaths['Week Ending Date'] - excessdeaths['Week Ending Date'].min()).dt.days\n",
    "all_ydata = excessdeaths['Number of Deaths'].values \n",
    "all_xdata = np.asarray(all_xdata)\n",
    "all_ydata = np.asarray(all_ydata)\n",
    "plt.figure(figsize=(12, 6)) \n",
    "\n",
    "fit_cosine_all_data = tilted_cosine(all_xdata, fit_A, fit_B, fit_C, fit_D, fit_E)\n",
    "\n",
    "plt.plot(all_xdata, all_ydata, '.', label='data')\n",
    "plt.plot(all_xdata, fit_cosine_all_data, '-', label='fit')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76708200-c148-44ec-9fcf-a384dafa538a",
   "metadata": {},
   "source": [
    "##### Next Steps\n",
    "- Historical model. What is acceptable SD for a given week? (Ask Winston/Aditya/Miranda about this).\n",
    "- Consider anything outside those bounds to be a signal. (this is for national govt context)\n",
    "- Fit model to all data (what was excluded).\n",
    "- Find the first week you would signal an alarm.\n",
    "- Reveal the true data --> give full context to the data\n",
    "\n",
    "\n",
    "##### More thought questions \n",
    "- National government ask what else could it be? How do you know this is related to COVID? -- come back to see what Winston had originally suggested in 4/1 meeting (notes lost in deleted notebook ): )\n",
    "- We've been building a model as if any given year is the same, and that's not true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa860fd-f7a4-49ca-946a-5552b4107483",
   "metadata": {},
   "source": [
    "Looking back now, ask student to give orders of understanding for each factor we added into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb12dc-a249-4e64-a180-2b99dde68ca5",
   "metadata": {},
   "source": [
    "## Part 3: Fermi problem (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744dad9c-7951-41ab-8e46-5ed06724dd49",
   "metadata": {},
   "source": [
    "The physics approach of connecting to unobvious things to find the value of another. Use excess deaths rate and XYZ, to find the population rate. (usually it's just something you search up)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0cf11-2e01-4f73-9929-1758e8f01668",
   "metadata": {},
   "source": [
    "## Part 4: Policymaking "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b93ec-5f01-42c6-b45c-7cd29ebd3913",
   "metadata": {},
   "source": [
    "Data 8 Lecture with Chief Data Scientist DJ Patil: https://data.berkeley.edu/news/dj-patil-calls-data-scientists-new-kind-first-responder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe17f6b-7e90-4f46-ba0b-5dfc2638b4b5",
   "metadata": {},
   "source": [
    "Not developed yet, would love any suggesstion/ideas if your still reading this far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c6fca-53b4-43f0-9f48-068fac981c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
